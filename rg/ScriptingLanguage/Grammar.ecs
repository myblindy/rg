#importMacros(Loyc.LLPG);

using System;
using System.Text;
using System.CodeDom.Compiler;
using System.Collections.Generic;
using System.Diagnostics;
using System.Linq;
using Loyc;              
using Loyc.Collections;  
using Loyc.Syntax.Lexing;
using Loyc.Syntax;       

namespace rg.ScriptingLanguage
{
	using TT = TokenType;  
	using S = CodeSymbols;
	using ES = ExtraCodeSymbols;

	static class ExtraCodeSymbols
	{
		public static readonly Symbol PrintSymbol = GSymbol.Get("'print");
	}

	// longer operators first
	replace (PUNCTUATION_TOKEN_LIST => (
		("<=", LE,        S.LE,		    TokenKind.Operator + 1),
		(">=", GE,        S.GE,		    TokenKind.Operator + 2),
		("==", Eq,        S.Eq,		    TokenKind.Operator + 3),
		("!=", NotEq,     S.NotEq,		TokenKind.Operator + 4),
		(">",  GT,        S.GT,		    TokenKind.Operator + 5),
		("<",  LT,        S.LT,		    TokenKind.Operator + 6),
		("=",  Assign,    S.Assign,	    TokenKind.Assignment),   
		("*",  Mul,       S.Mul,	    TokenKind.Operator + 7),
		("/",  Div,       S.Div,	    TokenKind.Operator + 8),
		("+",  Add,       S.Add,	    TokenKind.Operator + 9),
		("-",  Sub,       S.Sub,	    TokenKind.Operator + 10),
		("(",  LParen,    null,		    TokenKind.LParen),
		(")",  RParen,    null,		    TokenKind.RParen),
		("[",  LBrace,    null,		    TokenKind.LBrace),
		("]",  RBrace,    null,		    TokenKind.RBrace),
		("{",  LBrack,    null,		    TokenKind.LBrack),
		("}",  RBrack,    null,		    TokenKind.RBrack),
		(",",  Comma,     S.Comma,		TokenKind.Separator),
		(";",  Semicolon, S.Semicolon,  TokenKind.Separator),
		(":",  Colon,	  S.Colon,		TokenKind.Separator),

		("for",		ForEach, S.ForEach,			TokenKind.OtherKeyword + 1),
		("print",	Print,	 ES.PrintSymbol,	TokenKind.OtherKeyword + 2),
		));

	[GeneratedCode("ECS", null)]
	public enum TokenType
	{
		EOF = 0, 
		Spaces = TokenKind.Spaces + 1,
		Newline = TokenKind.Spaces + 2,
		Id  = TokenKind.Id,
		Num = TokenKind.Literal,
		unroll ((_, TOKEN_NAME, _V, TOKEN_KIND) in PUNCTUATION_TOKEN_LIST)
		{
			TOKEN_NAME = TOKEN_KIND;
		},
		Unknown
	}

	[GeneratedCode("ECS", null)]
	public static class TokenExt
	{
		// In this parser we'll use the predefined "Token" type in Loyc.Syntax.dll.
		// This extension method is defined because Token only has TypeInt, an integer.
		[DebuggerStepThrough]
		public static TT Type(this Token t) { return (TT)t.TypeInt; }
	}

	[GeneratedCode("ECS", null)]
	partial class MyLexer : BaseILexer<ICharSource, Token>
	{
		public MyLexer(UString text,     string fileName = "") : this((ICharSource)text, fileName) { }
		public MyLexer(ICharSource text, string fileName = "") : base(text, fileName) { }

		private new ISourceFile SourceFile => base.SourceFile;

		TT _type;
		object _value;
		int _startIndex;

		LLLPG (lexer);

		public override token Maybe<Token> NextToken()
		{
			_startIndex = InputPosition;
			_value = null;
			@[ {_type = TT.ForEach;}   ForEach
			 | {_type = TT.Print;}	   Print
			 | {_type = TT.Num;}       Num
			 | {_type = TT.Id;}        Id
			 | {_type = TT.Newline; }  Newline
			 | {_type = TT.Spaces;  }  (' '|'\t')+
			 | any punctuation
			 | error _? {return NoValue.Value;} 
			];
			return new Token((int)_type, _startIndex, InputPosition - _startIndex, NodeStyle.Default, _value);
		}

		// Newline is defined in the base class, but we have to tell LLLPG what it means
		extern token Newline @[ '\r' '\n'? | '\n' ];

		private token Id() @[
			('a'..'z'|'A'..'Z'|'_')
			('a'..'z'|'A'..'Z'|'_'|'0'..'9')*
			{_value = (Symbol)(CharSource.Slice(_startIndex, InputPosition - _startIndex).ToString());}
		];

		private token Num() @[
			{bool dot = false;}
			('.' {dot = true;})?
			'0'..'9'+
			(&!{dot} '.' '0'..'9'+)?
			{_value = double.Parse(CharSource.Slice(_startIndex, InputPosition - _startIndex).ToString());}
		];

		// Use 'unroll' to generate a rule for each operator token. Note: LLLPG 
		// and 'unroll' are unaware of each other, so we cannot use 'unroll' 
		// inside grammar code. So instead of using 'unroll' in NextToken(), I'm 
		// creating a separate rule for each possible operator token.
		unroll ((TEXT, TOKEN_NAME, TOKEN_VALUE, _) in PUNCTUATION_TOKEN_LIST)
		{
			// 'extern' prevents a method from being generated for the rule.
			// 'inline' causes this rule to be pasted wherever it is used.
			// 'punctuation' is not a keyword. It is an extra tag that is 
			// recognized by the 'any punctuation' command in NextToken().
			extern inline punctuation rule TOKEN_NAME() { 
				@[ TEXT ]; _type = TT.TOKEN_NAME; _value = TOKEN_VALUE;
			}
		}
	}

	[GeneratedCode("ECS", null)]
	public partial class MyParser : BaseParserForList<Token, int>
	{
		public static MyParser New(UString input) 
		{
			var lexer = new MyLexer(input);
			var tokens = new List<Token>();
			for (var next = lexer.NextToken(); next.HasValue; next = lexer.NextToken())
				if (next.Value.Kind != TokenKind.Spaces)
					tokens.Add(next.Value);
			return new MyParser(tokens, lexer.SourceFile);
		}

		public MyParser(IList<Token> list, ISourceFile file, int startIndex = 0) 
			: base(list, new Token((int)TT.EOF, 0, 0, null), file, startIndex) 
		{
			F = new LNodeFactory(file);
		}

		// BaseParser.Match() uses this for constructing error messages.
		protected override string ToString(int tokenType)
		{
			return ((TokenType)tokenType).ToString();
		}

		readonly LNodeFactory F;

		LNode BinOp(Symbol type, LNode lhs, LNode rhs) =>
			F.Call(type, lhs, rhs, lhs.Range.StartIndex, rhs.Range.EndIndex);

		LLLPG (parser(laType(TokenType), matchType(int)));

		// A parser cannot directly match characters. You can, however, use
		// aliases like «alias(":=" = TT.Assign);» to pretend that you're 
		// matching strings. In reality, you're still matching the tokens 
		// produced by the lexer. Here I use 'unroll' to make an alias for 
		// each operator and punctuation mark.
		unroll ((TEXT, TOKEN_NAME, _V, _K) in PUNCTUATION_TOKEN_LIST) {
			alias(TEXT = TT.TOKEN_NAME);
		}

		public rule LNode Start() @[ 
			stmts+:Statement* EOF {$result = F.Braces(stmts);}
		];

		private rule LNode Statement() @[
			( TT.ForEach "(" t:=TT.Id ":" Expr ")" "{" stmts+:Statement* "}" 
				{$result = F.Call(S.ForEach, F.Id(t), $Expr, F.Braces(stmts));}
			| TT.Print "(" Expr ")" ";" 
				{$result = F.Call(ES.PrintSymbol, $Expr);}
			| result:Expr ";"
			)
		];

		// Handle multiple precedence levels with one rule, as explained in Part 5 article
		private rule LNode Expr(int prec = 0) @[
			result:PrefixExpr
			greedy // to suppress ambiguity warning
			(   // Remember to add [Local] when your predicate uses a local variable
				&{[Local] prec <= 10}
				"[" index:=Expr() "]"
				{ $result = F.Call(S.IndexBracks, F.AltList($result, $index)); }
			|   &{[Local] prec <= 20}
				op:="=" r:=Expr(20)
				{ $result = BinOp((Symbol)op.Value, $result, r); }
			|   &{[Local] prec < 30}
				op:=(">"|"<"|">="|"<="|"=="|"!=") r:=Expr(30)
				{ $result = BinOp((Symbol)op.Value, $result, r); }
			|   &{[Local] prec < 40}
				op:=("+"|"-") r:=Expr(40)
				{ $result = BinOp((Symbol)op.Value, $result, r); }
			|   &{[Local] prec < 50}
				op:=("*"|"/") r:=Expr(50)
				{ $result = BinOp((Symbol)op.Value, $result, r); }
			)*
		];

		private rule LNode PrefixExpr() @
			[ minus:="-" Term {return F.Call(S.Sub, $Term, minus.StartIndex, $Term.Range.EndIndex);}
			| Term            {return $Term;}
			];

		private rule LNode Term() @[
			( t:=TT.Id              {$result = F.Id(t);}
			| t:=TT.Num             {$result = F.Literal(t);}
			| "[" "]"				{$result = F.AltList();}
			| "[" first:Expr ("," rest+:Expr)* "]" {$result = F.AltList($rest?.Prepend($first) ?? Enumerable.Repeat($first, 1));}
			| "(" result:Expr ")"   {$result = F.InParens($result);}
			| error                 {$result = F.Missing; Error(0, "Expected identifer, number, or (parens)");}
			)
		];
	}
}